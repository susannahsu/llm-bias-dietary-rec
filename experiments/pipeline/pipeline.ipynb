{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f45d01c9-06e9-4c7b-9cf2-6f6be67fc133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import nltk\n",
    "import zipfile\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from deep_translator import GoogleTranslator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35b11218-ef0a-4761-bfe2-240662e56017",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from collections import defaultdict\n",
    "\n",
    "import os\n",
    "import re\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fdf85ee-0bc6-4631-9cfd-2af60aff7f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:347: InconsistentVersionWarning: Trying to unpickle estimator LogisticRegression from version 1.2.2 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with open('best_logit_model.pkl', 'rb') as file:\n",
    "    clf = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36d2ed4-14bd-449d-b43b-56dba7be7a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = pickle.load(open(\"SVC-whats-cooking-trial-final.pickle.dat\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f20567d-ad13-49f1-92bb-cd31cec468cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load API key from .env file\n",
    "load_dotenv()\n",
    "\n",
    "key = os.getenv('OPENAI_API_KEY')\n",
    "if key is None:\n",
    "    raise ValueError(\"The OPENAI_API_KEY environment variable is not set \\\n",
    "                     or .env file is missing.\")\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3f6301-3c69-471b-bfe3-5c1393fe2b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_openai_api(user_prompt, system_prompt, n_runs=1, model=\"gpt-4-turbo-2024-04-09\"):\n",
    "    responses = []\n",
    "    for run_number in range(1, n_runs + 1):\n",
    "        completion = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt},\n",
    "            ],\n",
    "        )\n",
    "        response_content = completion.choices[0].message.content\n",
    "        print(response_content)\n",
    "        print(\"========================================next call\")\n",
    "        responses.append(response_content)\n",
    "    return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159e88da-9679-4c63-b2e0-3a71bd9dad95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_prompt_from_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return file.read()\n",
    "\n",
    "def generate_user_prompt(file_path):\n",
    "    return load_prompt_from_file(file_path)\n",
    "\n",
    "def generate_system_prompt(file_path):\n",
    "    return load_prompt_from_file(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1e5ac8-f194-45fe-a57b-3fc85e1f0f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt_path = 'user_prompt.txt'\n",
    "system_prompt_path = 'system_prompt.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f954067-c8d8-42fe-84a2-f8f6ec107371",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = generate_user_prompt(user_prompt_path)\n",
    "system_prompt = generate_system_prompt(system_prompt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bc5386-00b4-4a40-81cb-89039e9376dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = call_openai_api(user_prompt, system_prompt)\n",
    "responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba8b90f-2cb5-475e-96dc-1249b82ff6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_gpt_responses (gpt_responses):\n",
    "    # Removing enclosing list and replacing single quotes with double quotes for valid JSON\n",
    "    cleaned_data = gpt_responses[0].replace(\"'\", '\"')\n",
    "    \n",
    "    # Replacing newline and tabs if any (for cleaner JSON parsing)\n",
    "    cleaned_data = cleaned_data.replace(\"\\n\", \"\").replace(\"\\t\", \"\")\n",
    "    \n",
    "    # Load the string as JSON\n",
    "    try:\n",
    "        recipes = json.loads(cleaned_data)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"Error decoding JSON:\", e)\n",
    "        recipes = []\n",
    "    \n",
    "    # Transforming to the required format\n",
    "    processed_data = [{'name': recipe['name'], 'ingredients': recipe['ingredients']} for recipe in recipes]\n",
    "    \n",
    "    # Printing or saving the processed data\n",
    "    # print(json.dumps(processed_data, indent=2))\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a098824-36f0-4048-b8ec-45f6f19d6df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_df(df):\n",
    "    \n",
    "    def process_string(x):\n",
    "        x = [\" \".join([WordNetLemmatizer().lemmatize(q) for q in p.split()]) for p in x] #Lemmatization\n",
    "        x = list(map(lambda x: re.sub(r'\\(.*oz.\\)|crushed|crumbles|ground|minced|powder|chopped|sliced','', x), x))\n",
    "        x = list(map(lambda x: re.sub(\"[^a-zA-Z]\", \" \", x), x))   # To remove everything except a-z and A-Z\n",
    "        x = \" \".join(x)                                 # To make list element a string element \n",
    "        x = x.lower()\n",
    "        return x\n",
    "    \n",
    "    #df = df.drop('id',axis=1)\n",
    "    df['ingredients'] = df['ingredients'].apply(process_string)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa42e25-f4d6-440a-a152-9391c4ea8138",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pipeline(gpt_responses, vectorizer, model):\n",
    "    processed_responses = process_gpt_responses(gpt_responses)\n",
    "    df = pd.DataFrame(processed_responses)\n",
    "    test_df = preprocess_df(df)\n",
    "    test = test_df['ingredients']\n",
    "    test_transformed = vectorizer.transform(test)\n",
    "    prediction = model.predict(test_transformed)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22237dc7-68c1-443d-a67a-707e0887a22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tfidf_vectorizer.pkl', 'rb') as file:\n",
    "    vectorizer = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1467bc9f-54f3-4b0d-af82-fd73e522a9fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = process_pipeline(responses, vectorizer, clf)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72b2813-c5c6-46d0-932a-f0c331458ca1",
   "metadata": {},
   "source": [
    "### Chinese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47046eb7-baa9-4d4d-9081-5bc4d2abe190",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt_chn = generate_user_prompt('user_prompt_chn.txt')\n",
    "system_prompt_chn = generate_system_prompt('system_prompt_chn.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f9656a-8e6a-4937-b5c8-b3ed2e43002e",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_chn = call_openai_api(user_prompt_chn, system_prompt_chn)\n",
    "responses_chn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537e591e-3c60-4cfd-a9e1-17362fde30eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_to_eng(responses):\n",
    "    \n",
    "    translator = GoogleTranslator(source='auto', target='en')\n",
    "    translated_texts = []\n",
    "\n",
    "    for response in responses:\n",
    "        # Ensure the text does not exceed the 5000 character limit\n",
    "        if len(response) <= 5000:\n",
    "            try:\n",
    "                # Translate the text and convert to lowercase\n",
    "                translated = translator.translate(response).lower()\n",
    "                translated_texts.append(translated)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to translate text due to: {e}\")\n",
    "                translated_texts.append(\"Translation failed\")\n",
    "        else:\n",
    "            print(\"Text too long to translate:\", response)\n",
    "            translated_texts.append(\"Text too long and was not translated\")\n",
    "\n",
    "    return translated_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84764ded-035f-4b17-b64e-8fcd8a9ded50",
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_responses = translate_to_eng(responses_chn)\n",
    "translated_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aea0b53-bd85-4fa6-8f7c-d558a2be6408",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_chn = process_pipeline(translated_responses, vectorizer, clf)\n",
    "y_pred_chn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129eb4fb-fd2f-4971-bee2-19a7ee7dc8f2",
   "metadata": {},
   "source": [
    "### Brazilian (Portuguese)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5cda18-a9df-49f7-889d-d675b3f58496",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt_port = generate_user_prompt('user_prompt_port.txt')\n",
    "system_prompt_port = generate_system_prompt('system_prompt_port.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b1e650-bb5d-47c9-9119-1852ba5715b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_port = call_openai_api(user_prompt_port, system_prompt_port)\n",
    "responses_port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a32337a-5628-427c-a72d-186db457f1cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "translated_responses_port = translate_to_eng(responses_port)\n",
    "translated_responses_port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bdcdb0-5293-4ec7-aeb2-7a49f96074d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_port = process_pipeline(translated_responses_port, vectorizer, clf)\n",
    "y_pred_port"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60706d3-ba22-4aed-89e8-3f718a10721a",
   "metadata": {},
   "source": [
    "### Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca762a9-2cc6-4536-b925-9f7ae595d257",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_gpt_responses(gpt_responses):\n",
    "    all_processed_data = []\n",
    "    for response in gpt_responses:\n",
    "        # Clean and parse each response\n",
    "        cleaned_data = response.replace(\"'\", '\"').replace(\"\\n\", \"\").replace(\"\\t\", \"\")\n",
    "        try:\n",
    "            recipes = json.loads(cleaned_data)\n",
    "            processed_data = [{'name': recipe['name'], 'ingredients': recipe['ingredients']} for recipe in recipes]\n",
    "            all_processed_data.extend(processed_data)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(\"Error decoding JSON:\", e)\n",
    "    \n",
    "    return all_processed_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b84cc3-6b53-4eb0-b042-15622d9e5819",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pipeline(gpt_responses, vectorizer, model):\n",
    "    # Process all GPT responses and gather all recipes into a single DataFrame\n",
    "    processed_responses = process_gpt_responses(gpt_responses)\n",
    "    df = pd.DataFrame(processed_responses)\n",
    "    test_df = preprocess_df(df)\n",
    "    test = test_df['ingredients']\n",
    "    test_transformed = vectorizer.transform(test)\n",
    "    prediction = model.predict(test_transformed)\n",
    "    return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186da54a-d031-4cc3-bc3d-ed1d46f7fc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_responses_to_file(responses, filename=\"responses.json\"):\n",
    "\n",
    "    with open(filename, \"w\", encoding='utf-8') as f:\n",
    "        json.dump(responses, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a241239-3cab-48bf-8f82-83d4b09e0e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_responses_from_file(filename=\"responses.json\"):\n",
    "\n",
    "    with open(filename, \"r\", encoding='utf-8') as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582028c2-0183-4a30-8472-fe4ea3bc901a",
   "metadata": {},
   "source": [
    "#### Chinese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dee52c-a870-4a04-8e1c-597a33bbd72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_chn_2runs = call_openai_api(user_prompt_chn, system_prompt_chn, n_runs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4be9c6a-e1f4-4ded-aadc-e8df59f3361b",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_responses_to_file(responses_chn_5runs, \"responses_chn_2runs.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d095ed-543d-4238-b3b8-ab4fa8064694",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_responses = load_responses_from_file(\"responses_chn_2runs.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32145426-a1c6-462d-9bd1-64716e2388b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "translated_responses = translate_to_eng(loaded_responses)\n",
    "translated_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2195fbce-264b-4daa-9f7a-69068d88bf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_chn = process_pipeline(translated_responses, vectorizer, clf)\n",
    "y_pred_chn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50d43ae-e10a-4193-ad0d-adc9be3b7a7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f3fc8d-072b-4178-af27-ae9c4cc1d72f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
